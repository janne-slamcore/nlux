"use strict";var e=require("@nlux/hf"),t=require("react"),r=Object.defineProperty,s=(e,t,s)=>((e,t,s)=>t in e?r(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s)(e,"symbol"!=typeof t?t+"":t,s);class o extends Error{constructor(e={}){super(e.message),s(this,"exceptionId"),s(this,"message"),s(this,"source"),s(this,"type"),this.message=e.message??"",this.source=e.source,this.type=this.constructor.name,this.exceptionId=e.exceptionId}}class a extends o{}const n="hooks/getAdapterBuilder";Object.defineProperty(exports,"createChatAdapter",{enumerable:!0,get:function(){return e.createChatAdapter}}),Object.defineProperty(exports,"llama2InputPreProcessor",{enumerable:!0,get:function(){return e.llama2InputPreProcessor}}),Object.defineProperty(exports,"llama2OutputPreProcessor",{enumerable:!0,get:function(){return e.llama2OutputPreProcessor}}),exports.useChatAdapter=r=>{if(!r.model)throw new Error("You must provide either a model or an endpoint to use Hugging Face Inference API.");const[s,o]=t.useState(!1),[u]=t.useState((t=>{const{model:r,authToken:s,dataTransferMode:o,preProcessors:u,maxNewTokens:i,systemMessage:c}=t||{};if(o&&"stream"!==o&&"batch"!==o)throw new a({source:n,message:'Data transfer mode for Hugging Face Inference API must be either "stream" or "batch"'});if(void 0===r)throw new a({source:n,message:"You must provide either a model or an endpoint to use Hugging Face Inference API."});let d=e.createChatAdapter().withModel(r);return void 0!==s&&(d=d.withAuthToken(s)),void 0!==o&&(d=d.withDataTransferMode(o)),void 0!==u?.input&&(d=d.withInputPreProcessor(u.input)),void 0!==u?.output&&(d=d.withOutputPreProcessor(u?.output)),void 0!==c&&(d=d.withSystemMessage(c)),void 0!==i&&(d=d.withMaxNewTokens(i)),d})(r).create()),{authToken:i,dataTransferMode:c,model:d,systemMessage:p,preProcessors:{input:h,output:m}={},maxNewTokens:l}=r||{};return t.useEffect(()=>{s||o(!0)},[i,c,d,p,h,m,l]),u};
