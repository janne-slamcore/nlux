"use strict";var e=require("openai");const t=e=>{"string"!=typeof e?e&&"function"==typeof e.toString?console.warn(`[nlux] ${e.toString()}`):console.warn("[nlux]"):console.warn(`[nlux] ${e}`)},s=[];var a=Object.defineProperty,r=(e,t,s)=>((e,t,s)=>t in e?a(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s)(e,"symbol"!=typeof t?t+"":t,s);class o extends Error{constructor(e={}){super(e.message),r(this,"exceptionId"),r(this,"message"),r(this,"source"),r(this,"type"),this.message=e.message??"",this.source=e.source,this.type=this.constructor.name,this.exceptionId=e.exceptionId}}class i extends o{}const n=e=>{if("object"==typeof e&&null!==e){const t=e;if("invalid_api_key"===t.code)return"invalid-api-key";if(t.message?.toLowerCase().includes("connection error"))return"connection-error"}return null},l=e=>e.map(e=>{let s;if("string"==typeof e.message||"number"===e.message?s=`${e.message}`:"object"===e.message&&(s=JSON.stringify(e.message)),void 0!==s)return{role:e.role,content:s};t("Empty message or unsupported message format found in conversation history and will not be included in the conversation history sent to OpenAI.")}).filter(e=>void 0!==e),c=Object.freeze({id:"nlux-openai-adapter",capabilities:{chat:!0,fileUpload:!1,speechToText:!1,textToSpeech:!1}}),h="stream";var d=Object.defineProperty,m=(e,t,s)=>((e,t,s)=>t in e?d(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s)(e,"symbol"!=typeof t?t+"":t,s);class u{constructor({systemMessage:s,apiKey:a,dataTransferMode:r,model:o}){m(this,"model"),m(this,"openai"),m(this,"systemMessage","Act as a helpful assistant to the user"),m(this,"theDataTransferMode"),m(this,"__instanceId"),this.__instanceId=`${this.info.id}-${"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx".replace(/[xy]/g,e=>{const t=16*Math.random()|0;return("x"==e?t:3&t|8).toString(16)})}`,this.theDataTransferMode=r??h,this.model=o??"gpt-4-turbo",this.openai=new e({apiKey:a,dangerouslyAllowBrowser:!0}),s&&(this.systemMessage=s),t('OpenAI GPT adapter has been initialized in browser mode using option "dangerouslyAllowBrowser". To learn more about OpenAI\' recommendation for handling API keys, please visit:\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\nThe useUnsafeChatAdapter/createUnsafeChatAdapter are only intended for development and testing purposes.\n\nFor production use, we recommend that you implement a server-side proxy and configure a customized adapter for it. To learn more about how to create custom adapters for nlux, visit:\nhttps://docs.nlkit.com/nlux/learn/adapters/custom-adapters')}get dataTransferMode(){return this.theDataTransferMode}get id(){return this.__instanceId}get info(){return c}preProcessAiBatchedMessage(e,s){try{return(e=>{if(!e.choices||!e.choices[0])throw Error("Invalid payload");const t=e.choices[0].message?.content;if(null!==t)return t})(e)}catch(e){return t("Error while decoding batched message"),void t(e)}}preProcessAiStreamedChunk(e,s){try{return(e=>{if(!e.choices||!e.choices[0])throw Error("Invalid payload");const t=e.choices[0].delta.content;if("string"==typeof t)return t})(e)}catch(e){return t("Error while decoding streamed chunk"),void t(e)}}}class p extends u{constructor({apiKey:e,model:t,systemMessage:s}){super({apiKey:e,model:t,systemMessage:s,dataTransferMode:"batch"}),void 0!==s&&s.length>0&&(this.systemMessage=s)}async batchText(e,s){const a=this.systemMessage?[{role:"system",content:this.systemMessage}]:[];if(s.conversationHistory){const e=l(s.conversationHistory);a.push(...e)}a.push({role:"user",content:e});try{return await this.openai.chat.completions.create({stream:!1,model:this.model,messages:a})}catch(e){t("Error while making API call to OpenAI"),t(e);const s=e?.message;throw new i({source:this.constructor.name,message:s??"Error while making API call to OpenAI",exceptionId:n(e)??void 0})}}streamText(e,t,s){throw new i({source:this.constructor.name,message:"Cannot stream text from the batch adapter!"})}}class y extends u{constructor({apiKey:e,model:t,systemMessage:s}){super({apiKey:e,model:t,systemMessage:s,dataTransferMode:"stream"}),void 0!==s&&s.length>0&&(this.systemMessage=s)}batchText(e){throw new i({source:this.constructor.name,message:"Cannot fetch text from the streaming adapter!"})}streamText(e,s,a){const r=this.systemMessage?[{role:"system",content:this.systemMessage}]:[];if(a.conversationHistory){const e=l(a.conversationHistory).map(e=>({content:"string"==typeof e.content?e.content:JSON.stringify(e.content),role:e.role}));r.push(...e)}r.push({role:"user",content:e}),this.openai.chat.completions.create({stream:!0,model:this.model,messages:r}).then(async e=>{const t=e[Symbol.asyncIterator]();let a=await t.next();for(;!a.done;){const e=a.value;if("stop"===(e.choices?.length>0?e.choices[0].finish_reason:void 0))break;s.next(e),a=await t.next()}s.complete()}).catch(e=>{t(e),s.error(new i({source:this.constructor.name,message:e.message,exceptionId:n(e)??void 0}))})}}var g=Object.defineProperty,f=(e,t,s)=>((e,t,s)=>t in e?g(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s)(e,"symbol"!=typeof t?t+"":t,s);class w{constructor(e){f(this,"apiKey",null),f(this,"dataTransferMode",h),f(this,"model",null),f(this,"systemMessage",null),f(this,"withApiKeyCalled",!1),f(this,"withDataTransferModeCalled",!1),f(this,"withModelCalled",!1),f(this,"withSystemMessageCalled",!1),e&&(this.apiKey=e.apiKey,this.dataTransferMode=e.dataTransferMode,this.model=e.model,this.systemMessage=e.systemMessage,this.withApiKeyCalled=e.withApiKeyCalled,this.withSystemMessageCalled=e.withSystemMessageCalled,this.withModelCalled=e.withModelCalled,this.withDataTransferModeCalled=e.withDataTransferModeCalled)}create(){if(!this.apiKey)throw new i({source:this.constructor.name,message:"Unable to create OpenAI adapter. API key is missing. Make sure you are calling withApiKey() before calling create()."});const e={apiKey:this.apiKey,dataTransferMode:this.dataTransferMode,model:this.model??void 0,systemMessage:this.systemMessage??void 0};return"stream"===this.dataTransferMode?new y(e):new p(e)}withApiKey(e){if(this.withApiKeyCalled)throw new i({source:this.constructor.name,message:"Unable to set API key. API key setter has already been called by this builder. Make sure you are not calling withApiKey() twice."});return this.apiKey=e,this.withApiKeyCalled=!0,this}withDataTransferMode(e){if(this.withDataTransferModeCalled)throw new i({source:this.constructor.name,message:"Unable to set data loading mode. Stream or fetch setter has already been called by this builder. Make sure you are not calling stream() or fetch() twice."});return this.dataTransferMode=e,this.withDataTransferModeCalled=!0,this}withModel(e){if(this.withModelCalled)throw new i({source:this.constructor.name,message:"Unable to set model. Model setter has already been called by this builder. Make sure you are not calling withModel() twice."});return this.model=e,this.withModelCalled=!0,this}withSystemMessage(e){if(this.withSystemMessageCalled)throw new i({source:this.constructor.name,message:"Unable to set initial system message. Initial system message setter has already been called by this builder. Make sure you are not calling withSystemMessage() twice."});return this.systemMessage=e??null,this.withSystemMessageCalled=!0,this}}exports.createUnsafeChatAdapter=()=>{var e;return e="You just have created an OpenAI adapter that connects to the API directly from the browser. This is not recommended for production use. We recommend that you implement a server-side proxy and configure a customized adapter for it. To learn more about how to create custom adapters for nlux, visit:\nhttps://docs.nlkit.com/nlux/learn/adapters/custom-adapters",s.includes(e)||(s.push(e),t(e)),new w};
