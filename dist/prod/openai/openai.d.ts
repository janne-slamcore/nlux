import { DataTransferMode, ChatAdapterBuilder as ChatAdapterBuilder$1, StandardChatAdapter } from '@nlux/core';
export { ChatAdapter, DataTransferMode, StandardChatAdapter, StreamingAdapterObserver } from '@nlux/core';

type OpenAiModel = (string & NonNullable<unknown>) | 'gpt-4o' | 'gpt-4o-2024-05-13' | 'gpt-4-turbo' | 'gpt-4-turbo-2024-04-09' | 'gpt-4-0125-preview' | 'gpt-4-turbo-preview' | 'gpt-4-1106-preview' | 'gpt-4-vision-preview' | 'gpt-4' | 'gpt-4-0314' | 'gpt-4-0613' | 'gpt-4-32k' | 'gpt-4-32k-0314' | 'gpt-4-32k-0613' | 'gpt-3.5-turbo' | 'gpt-3.5-turbo-16k' | 'gpt-3.5-turbo-0301' | 'gpt-3.5-turbo-0613' | 'gpt-3.5-turbo-1106' | 'gpt-3.5-turbo-0125' | 'gpt-3.5-turbo-16k-0613';

type ChatAdapterOptions = {
    dataTransferMode?: DataTransferMode;
    model?: OpenAiModel;
    apiKey: string;
    systemMessage?: string;
};

interface ChatAdapterBuilder<AiMsg> extends ChatAdapterBuilder$1<AiMsg> {
    /**
     * Create a new ChatGPT API adapter.
     * Adapter users don't need to call this method directly. It will be called by nlux when the adapter is expected
     * to be created.
     *
     * @returns {StandardChatAdapter}
     */
    create(): StandardChatAdapter<AiMsg>;
    /**
     * The API key to use to connect to ChatGPT API.
     * This is secret and should not be shared publicly or hosted when deploying your application.
     *
     * @optional
     * @param {string} apiKey
     * @returns {ChatAdapterBuilder}
     */
    withApiKey(apiKey: string): ChatAdapterBuilder<AiMsg>;
    /**
     * Instruct the adapter to connect to API and load data either in streaming mode or in batch mode.
     * The `stream` mode would use protocols such as websockets or server-side events, and nlux will display data as
     * it's being generated by the server. The `batch` mode would use a single request to fetch data, and the response
     * would only be displayed once the entire message is loaded.
     *
     * @optional
     * @default 'stream'
     * @returns {ChatAdapterBuilder}
     */
    withDataTransferMode(mode: DataTransferMode): ChatAdapterBuilder<AiMsg>;
    /**
     * The model or the endpoint to use for ChatGPT Inference API.
     * You should provide either a model or an endpoint, but not both.
     *
     * @param {string} model
     * @returns {ChatAdapterBuilder}
     */
    withModel(model: string): ChatAdapterBuilder<AiMsg>;
    /**
     * The initial system to send to ChatGPT API.
     *
     * @optional
     * @param {string} message
     * @returns {ChatAdapterBuilder}
     */
    withSystemMessage(message: string): ChatAdapterBuilder<AiMsg>;
}

declare const createUnsafeChatAdapter: <AiMsg = string>() => ChatAdapterBuilder<AiMsg>;

export { createUnsafeChatAdapter };
export type { ChatAdapterBuilder, ChatAdapterOptions, OpenAiModel };
