!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports,require("openai")):"function"==typeof define&&define.amd?define(["exports","openai"],t):t((e="undefined"!=typeof globalThis?globalThis:e||self)["@nlux/openai"]={},e.OpenAI)}(this,function(e,t){"use strict";const s=e=>{"string"!=typeof e?e&&"function"==typeof e.toString?console.warn(`[nlux] ${e.toString()}`):console.warn("[nlux]"):console.warn(`[nlux] ${e}`)},a=[];var o=Object.defineProperty,r=(e,t,s)=>((e,t,s)=>t in e?o(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s)(e,"symbol"!=typeof t?t+"":t,s);class n extends Error{constructor(e={}){super(e.message),r(this,"exceptionId"),r(this,"message"),r(this,"source"),r(this,"type"),this.message=e.message??"",this.source=e.source,this.type=this.constructor.name,this.exceptionId=e.exceptionId}}class i extends n{}const l=e=>{if("object"==typeof e&&null!==e){const t=e;if("invalid_api_key"===t.code)return"invalid-api-key";if(t.message?.toLowerCase().includes("connection error"))return"connection-error"}return null},c=e=>e.map(e=>{let t;if("string"==typeof e.message||"number"===e.message?t=`${e.message}`:"object"===e.message&&(t=JSON.stringify(e.message)),void 0!==t)return{role:e.role,content:t};s("Empty message or unsupported message format found in conversation history and will not be included in the conversation history sent to OpenAI.")}).filter(e=>void 0!==e),h=Object.freeze({id:"nlux-openai-adapter",capabilities:{chat:!0,fileUpload:!1,speechToText:!1,textToSpeech:!1}}),d="stream";var m=Object.defineProperty,u=(e,t,s)=>((e,t,s)=>t in e?m(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s)(e,"symbol"!=typeof t?t+"":t,s);class p{constructor({systemMessage:e,apiKey:a,dataTransferMode:o,model:r}){u(this,"model"),u(this,"openai"),u(this,"systemMessage","Act as a helpful assistant to the user"),u(this,"theDataTransferMode"),u(this,"__instanceId"),this.__instanceId=`${this.info.id}-${"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx".replace(/[xy]/g,e=>{const t=16*Math.random()|0;return("x"==e?t:3&t|8).toString(16)})}`,this.theDataTransferMode=o??d,this.model=r??"gpt-4-turbo",this.openai=new t({apiKey:a,dangerouslyAllowBrowser:!0}),e&&(this.systemMessage=e),s('OpenAI GPT adapter has been initialized in browser mode using option "dangerouslyAllowBrowser". To learn more about OpenAI\' recommendation for handling API keys, please visit:\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\nThe useUnsafeChatAdapter/createUnsafeChatAdapter are only intended for development and testing purposes.\n\nFor production use, we recommend that you implement a server-side proxy and configure a customized adapter for it. To learn more about how to create custom adapters for nlux, visit:\nhttps://docs.nlkit.com/nlux/learn/adapters/custom-adapters')}get dataTransferMode(){return this.theDataTransferMode}get id(){return this.__instanceId}get info(){return h}preProcessAiBatchedMessage(e,t){try{return(e=>{if(!e.choices||!e.choices[0])throw Error("Invalid payload");const t=e.choices[0].message?.content;if(null!==t)return t})(e)}catch(e){return s("Error while decoding batched message"),void s(e)}}preProcessAiStreamedChunk(e,t){try{return(e=>{if(!e.choices||!e.choices[0])throw Error("Invalid payload");const t=e.choices[0].delta.content;if("string"==typeof t)return t})(e)}catch(e){return s("Error while decoding streamed chunk"),void s(e)}}}class y extends p{constructor({apiKey:e,model:t,systemMessage:s}){super({apiKey:e,model:t,systemMessage:s,dataTransferMode:"batch"}),void 0!==s&&s.length>0&&(this.systemMessage=s)}async batchText(e,t){const a=this.systemMessage?[{role:"system",content:this.systemMessage}]:[];if(t.conversationHistory){const e=c(t.conversationHistory);a.push(...e)}a.push({role:"user",content:e});try{return await this.openai.chat.completions.create({stream:!1,model:this.model,messages:a})}catch(e){s("Error while making API call to OpenAI"),s(e);const t=e?.message;throw new i({source:this.constructor.name,message:t??"Error while making API call to OpenAI",exceptionId:l(e)??void 0})}}streamText(e,t,s){throw new i({source:this.constructor.name,message:"Cannot stream text from the batch adapter!"})}}class f extends p{constructor({apiKey:e,model:t,systemMessage:s}){super({apiKey:e,model:t,systemMessage:s,dataTransferMode:"stream"}),void 0!==s&&s.length>0&&(this.systemMessage=s)}batchText(e){throw new i({source:this.constructor.name,message:"Cannot fetch text from the streaming adapter!"})}streamText(e,t,a){const o=this.systemMessage?[{role:"system",content:this.systemMessage}]:[];if(a.conversationHistory){const e=c(a.conversationHistory).map(e=>({content:"string"==typeof e.content?e.content:JSON.stringify(e.content),role:e.role}));o.push(...e)}o.push({role:"user",content:e}),this.openai.chat.completions.create({stream:!0,model:this.model,messages:o}).then(async e=>{const s=e[Symbol.asyncIterator]();let a=await s.next();for(;!a.done;){const e=a.value;if("stop"===(e.choices?.length>0?e.choices[0].finish_reason:void 0))break;t.next(e),a=await s.next()}t.complete()}).catch(e=>{s(e),t.error(new i({source:this.constructor.name,message:e.message,exceptionId:l(e)??void 0}))})}}var g=Object.defineProperty,w=(e,t,s)=>((e,t,s)=>t in e?g(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s)(e,"symbol"!=typeof t?t+"":t,s);class x{constructor(e){w(this,"apiKey",null),w(this,"dataTransferMode",d),w(this,"model",null),w(this,"systemMessage",null),w(this,"withApiKeyCalled",!1),w(this,"withDataTransferModeCalled",!1),w(this,"withModelCalled",!1),w(this,"withSystemMessageCalled",!1),e&&(this.apiKey=e.apiKey,this.dataTransferMode=e.dataTransferMode,this.model=e.model,this.systemMessage=e.systemMessage,this.withApiKeyCalled=e.withApiKeyCalled,this.withSystemMessageCalled=e.withSystemMessageCalled,this.withModelCalled=e.withModelCalled,this.withDataTransferModeCalled=e.withDataTransferModeCalled)}create(){if(!this.apiKey)throw new i({source:this.constructor.name,message:"Unable to create OpenAI adapter. API key is missing. Make sure you are calling withApiKey() before calling create()."});const e={apiKey:this.apiKey,dataTransferMode:this.dataTransferMode,model:this.model??void 0,systemMessage:this.systemMessage??void 0};return"stream"===this.dataTransferMode?new f(e):new y(e)}withApiKey(e){if(this.withApiKeyCalled)throw new i({source:this.constructor.name,message:"Unable to set API key. API key setter has already been called by this builder. Make sure you are not calling withApiKey() twice."});return this.apiKey=e,this.withApiKeyCalled=!0,this}withDataTransferMode(e){if(this.withDataTransferModeCalled)throw new i({source:this.constructor.name,message:"Unable to set data loading mode. Stream or fetch setter has already been called by this builder. Make sure you are not calling stream() or fetch() twice."});return this.dataTransferMode=e,this.withDataTransferModeCalled=!0,this}withModel(e){if(this.withModelCalled)throw new i({source:this.constructor.name,message:"Unable to set model. Model setter has already been called by this builder. Make sure you are not calling withModel() twice."});return this.model=e,this.withModelCalled=!0,this}withSystemMessage(e){if(this.withSystemMessageCalled)throw new i({source:this.constructor.name,message:"Unable to set initial system message. Initial system message setter has already been called by this builder. Make sure you are not calling withSystemMessage() twice."});return this.systemMessage=e??null,this.withSystemMessageCalled=!0,this}}e.createUnsafeChatAdapter=()=>{var e;return e="You just have created an OpenAI adapter that connects to the API directly from the browser. This is not recommended for production use. We recommend that you implement a server-side proxy and configure a customized adapter for it. To learn more about how to create custom adapters for nlux, visit:\nhttps://docs.nlkit.com/nlux/learn/adapters/custom-adapters",a.includes(e)||(a.push(e),s(e)),new x}});
